{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapas executadas da tarefa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Leitura do conjunto de dados census.csv;\n",
    "\n",
    "* Verificaçãose todas a linhas do dataframe contêm valores;\n",
    "\n",
    "* Observou-se que o número de amostras do conjunto de dados é 5533 e na contagem de dados das variáveis contínuas do *dataset* temos um valor faltante para as variáveis *capital-gain*, *capital-loss* e *hours-per-week*. Como foram identificados valores faltantes em apenas uma linha (inclusive o rótulo estava sem valor), a mesma foi eliminada.\n",
    "\n",
    "* Foi feito um *pairplot* para analisar a relação das variáveis duas a duas e identificar possíveis *outliers*. Foi possível observar no *pairplot* das variáveis contínuas que as variáveis *capital-gain* e *capital-loss* apresentavam distribuições enviesadas (com pouca variância, dificultando a separação entre as duas classes desejadas). Para evitar os *outliers* foi feita uma transformação logarítmica nessas duas colunas a fim de comprimir os dados em um intervalo menores valores;\n",
    "\n",
    "* Em seguida, as variáveis numéricas foram normalizadas de modo que ficassem no intervalo [0, 1] e dessa forma todos os dados de entrada estariam na mesma escala (alguns algoritmos de *Machine Learning* são variantes à escala). A equação de normalização usada foi:\n",
    "\n",
    "$$\\ x_{scaled}=\\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "* Visto que a variável *occupation* é irregular e pode atrapalhar na classificação, uma vez que não segue valores padronizados, ela foi ignorada. Como para cada valor de *education_level* temos um valor correspondente em *education-num*, essas informações são redundantes e, por isso, vamos ignorar a coluna categórica *education_level*.\n",
    "\n",
    "* O próximo passo foi codificar as variáveis categóricas usando a técnica *Binary Encoding*, que em comparação à codificação em variáveis *dummy*, gera dados de menor dimensão. Portanto, ao realizar a codificação das variáveis categóricas em *Binary Encoding* acabou-se gerando novas variáveis, a fim de que as variáveis categóricas originais pudessem ser representadas numericamente e, assim, entendidas pelos algoritmos de *Machine Learning* que poderiam precisar.\n",
    "\n",
    "* Uma vez que o conjunto de dados está limpo, iniciou-se a etapa de modelagem de *Machine Learning* para realizar o processo de classificação.\n",
    "\n",
    "* A ideia foi testar 3 algoritmos supervisionados: Árvore de Decisão (*Decision tree*), Floresta Aleatória (*Random Forest*) e Máquina de Vetores Suporte (*SVM - Support Vector Machine*).\n",
    "\n",
    "* Para treinar o modelo, o conjunto de dados foi separado em dados de treino e de teste. Foi feito um *k-fold cross-validation* com *k* = 10 para os três algoritmos, sendo que os dados de treino separados inicialmente foram separado ainda em um menor conjunto de treino e um de validação para realizar o *k-fold cross-validation*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para o algoritmo *Decision Tree* foi feito um *Grid* com variação dos parâmetros de profundidade máxima da árvore gerada e e o número máximo de *features* usadas para construí-la. Os melhores parâmetros para a *Decision Tree* foram {'max_depth': 5, 'max_features': 4}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'max_depth': [1, 2, 3, 4, 5],\n",
    "                  'max_features': [1, 2, 3, 4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para o algoritmo *Random Forest* foi feito um *Grid* com variação dos parâmetros de profundidade máxima da floresta (conjunto de árvores combinadas), número de estimadores e critério de parada. Os melhores parâmetros para a *Random Forest* foram {'max_features': 4, 'n_estimators': 25, 'criterion': 'entropy'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'n_estimators': [10, 25, 50, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_features': [1, 2, 3, 4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para o algoritmo *SVM* foi feito um *Grid* com variação do parâmetro *C* e da função *kernel* usada. Os melhores parâmetros para a *SVM* foram {'C': 100, 'kernel': 'linear'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                             | Decision Tree    | Random Forest    |   SVM   |\n",
    "|-----------------------------|---------------   |---------------   |-------- |\n",
    "| Acurácia                    |      79.25%      |      82.98%      |  82.62% |\n",
    "| Log loss (entropia cruzada) |       6.29       |       5.64       |  5.89   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se pode observar na tabel acima, a maior taxa de acurácia foi alcançada pelo *Random Forest*, bem como teve sua função perda *Log loss* com menor valor. Entretanto, houve uma pequena diferença em relação ao *SVM* em termos de acurácia e, além disso, o *Random Forest* é um algoritmo mais demorado para ser treinado. Já era esperado que a *Decision Tree* fosse ter uma taxa  de acurácia inferior aos demais, uma vez que é apenas uma árvore que é contruída, enquanto no *Random Forest* são criadas várias árvores de decisão e estas são mescladas para se obter uma previsão mais precisa e estável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
